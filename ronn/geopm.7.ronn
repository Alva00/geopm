geopm(7) -- global energy optimization power management
=======================================================

[//]: # (Copyright (c) 2015, 2016, Intel Corporation)
[//]: # ()
[//]: # (Redistribution and use in source and binary forms, with or without)
[//]: # (modification, are permitted provided that the following conditions)
[//]: # (are met:)
[//]: # ()
[//]: # (    * Redistributions of source code must retain the above copyright)
[//]: # (      notice, this list of conditions and the following disclaimer.)
[//]: # ()
[//]: # (    * Redistributions in binary form must reproduce the above copyright)
[//]: # (      notice, this list of conditions and the following disclaimer in)
[//]: # (      the documentation and/or other materials provided with the)
[//]: # (      distribution.)
[//]: # ()
[//]: # (    * Neither the name of Intel Corporation nor the names of its)
[//]: # (      contributors may be used to endorse or promote products derived)
[//]: # (      from this software without specific prior written permission.)
[//]: # ()
[//]: # (THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS)
[//]: # ("AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT)
[//]: # (LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR)
[//]: # (A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT)
[//]: # (OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,)
[//]: # (SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT)
[//]: # (LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,)
[//]: # (DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY)
[//]: # (THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT)
[//]: # ((INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY LOG OF THE USE)
[//]: # (OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.)

## DESCRIPTION
Global Energy Optimization Power Management (GEOPM) is an extensible power
management framework targeting high performance computing.  The library can be
extended to support new control algorithms and new hardware power management
features.  The GEOPM package provides built in features ranging from static
management of power policy for each individual compute node, to dynamic
coordination of power policy and performance across all of the compute nodes
hosting one MPI job on a portion of a distributed computing system.  The
dynamic coordination is implemented as a hierarchical control system for
scalable communication and decentralized control.  The hierarchical control
system can optimize for various objective functions including maximizing
global application performance within a power bound.  The root of the control
hierarchy tree can communicate through shared memory with the system resource
management daemon to extend the hierarchy above the individual MPI job level
and enable management of system power resources for multiple MPI jobs and
multiple users by the system resource manager.  The geopm package provides the
libgeopm library, the libgeopmpolicy library, the geopmctl application and the
geopmpolicy application.  The libgeopm library can be called within MPI
applications to enable application feedback for informing the control
decisions.  If modification of the target application is not desired then the
geopmctl application can be run concurrently with the target application.  In
this case, target application feedback is inferred by querying the hardware
through Model Specific Registers (MSRs).  With either method (libgeopm or
geopmctl), the control hierarchy tree writes processor power policy through
MSRs to enact policy decisions.  The libgeopmpolicy library is used by a
resource manager to set energy policy control parameters for MPI jobs.  Some
features of libgeopmpolicy are available through the geopmpolicy application
including support for static control.

## LAUNCHING THE RUNTIME
pass

## INTERPRETING THE REPORT
pass

## INTERPRETING THE TRACE
pass

## ENVIRONMENT
  * `GEOPM_TRACE`:
    Enables geopm tracing capability.  Setting this variable enables
    the creation of a trace output file. The value of the variable
    is used as the base of the output trace file path.  Currently one
    trace file is generated per compute node.  The file names of each
    trace are constructed by appending the node's hostname to base
    name given by the environment variable (separated by a '-').

  * `GEOPM_SHMKEY`:
    Override the default shared memory key base.  The shared memory
    key base prefixes all shared memory keys used by geopm to
    communicate between the compute application and the geopm runtime.
    The default key base is '/geopm-default', this can be overridden
    by the environment variable, and the environment can be overridden
    by specifying a non-null and matching shm_key parameter to
    `geopm_ctl_create`() and `geopm_prof_create`().  The base key is
    extended for each shared memory region used by the runtime.  A
    simple command to clean up after an aborted job:

    `$ test -n "$GEOPM_SHMKEY" && rm -f /dev/shm${GEOPM_SHMKEY}* || rm -f /dev/shm/geopm-default*`

  * `GEOPM_POLICY`:
    Defines the default policy. The value is either a shared memory
    key or json file path.  This environment variable must be set when
    launching the geopm controller through the PMPI interface (see
    GEOPM_PMPI_CTL environment variable below).  A shared memory key
    must begin with the '/' character and have no other occurrence of
    the '/' character.  All other values are assumed to refer to a
    json file path.  When using a shared memory policy the resource
    manager creates the shared memory region and dynamically controls
    the global policy by modifying the region at runtime.

  * `GEOPM_PMPI_CTL`:
    When set to 'process' or 'pthread' this environment variable
    enables the launch of the geopm controller through the PMPI
    wrappers: in particular the wrappers for MPI_Init() or
    MPI_Init_thread().  In the case of specifying 'process' the
    controller will run as separate processes on a split off
    communicator comprised of the lowest rank on each node.
    Additionally through interception with the PMPI wrappers, the
    application MPI_COMM_WORLD appears to have one fewer rank per node
    than was allocated to the job.  In the case of specifying
    'pthread' the lowest rank on each node will launch a pthread
    running the controller.  The pthread launch mechanism requires an
    MPI runtime that can support MPI_THREAD_MULTIPLE.

  * `GEOPM_PLUGIN_PATH`:
    The search path for geopm plugins.  It is a colon-separated list
    of directories used by geopm to search for shared objects which
    contain geopm plugins.  A zero-length directory name indicates the
    current working directory.  A zero-length directory is inferred by
    a leading or trailing colon or two adjacent colons.  The default
    search location is always searched and is determined at library
    configuration time and by way of the 'pkglib' variable (typically
    /usr/lib64/geopm/).

  * `GEOPM_REGION_BARRIER`:
    Enables a node local MPI_Barrier() at time of calling
    `geopm_region_enter`() or `geopm_region_exit`() for all
    application ranks that share a node.  Since the geopm controller
    only considers a region to be entered when all ranks on a node
    have entered the region, enabling this feature forces control
    throughout all of the time every rank spends in a region.  This
    feature is primarily used for debugging purposes.  WARNING: If all
    regions marked in the application are not entered synchronously by
    all ranks on a node then enabling this feature will cause a
    deadlock and the application will hang.

  * `GEOPM_ERROR_AFFINITY_IGNORE`:
    If set, errors of the type GEOPM_ERROR_AFFINITY are ignored by
    geopm.  This is useful for testing on systems where CPU affinity
    requirements cannot be met (e.g. Mac OS X). See `geopm_error`(3)
    for more information on this error condition.

## COPYRIGHT
Copyright (C) 2015, 2016, Intel Corporation. All rights reserved.

## SEE ALSO
**geopmkey(1)**,
**geopm_comm(3)**,
**geopm_ctl_c(3)**,
**geopm_error(3)**,
**geopm_fortran(3)**,
**geopm_omp(3)**,
**geopm_policy_c(3)**,
**geopm_prof_c(3)**,
**geopm_version(3)**,
**geopmctl(1)**,
**geopmpolicy(1)**
